{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import lightgbm as lgb\n",
    "\n",
    "work_path = \"xxx\"\n",
    "sys.path.append(f\"xxx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "\n",
    "# x, yともに適用する処理\n",
    "# x, yそれぞれに適用する処理\n",
    "    x = x.select(pl.exclude(\"Scientific name\"))\n",
    "    x = x.select(~ pl.selectors.ends_with(\"records\"))\n",
    "\n",
    "\n",
    "    x = x.select([\"xxx\", \"xxx\"])\n",
    "\n",
    "\n",
    "    global train_type\n",
    "    # train_type = \"full\"\n",
    "\n",
    "    train_type = \"no_max\"\n",
    "    x = x.select(pl.exclude('xxx'))\n",
    "    \n",
    "    # x = x.select(pl.exclude(pl.Utf8))\n",
    "    x = x.with_columns(\n",
    "        pl.when(pl.col(pl.Utf8).is_null())\n",
    "        .then(pl.lit(0))\n",
    "        .when(pl.col(pl.Utf8) == \"Y\")\n",
    "        .then(pl.lit(1))\n",
    "        .name.keep()\n",
    "    )\n",
    "\n",
    "    ys = df.select([\"xxx\"])\n",
    "\n",
    "    # NとYを0, 1に置き換え\n",
    "    ys = ys.with_columns(\n",
    "        pl.when(pl.all().is_null())\n",
    "        .then(pl.lit(0))\n",
    "        .when(pl.all() == \"Y\")\n",
    "        .then(pl.lit(1))\n",
    "        .name.keep()\n",
    "    )\n",
    "    \n",
    "    return x, ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pl.read_csv(Path(\"xxx.csv\"), infer_schema_length=1000)\n",
    "df_test = pl.read_csv(Path(\"yyy.csv\"), infer_schema_length=1000)\n",
    "\n",
    "new_dtypes = pl.concat([df_train, df_test], how=\"diagonal_relaxed\").dtypes\n",
    "\n",
    "df_train = df_train.cast({k: v for k, v in zip(df_train.columns, new_dtypes)})\n",
    "df_test = df_test.cast({k: v for k, v in zip(df_test.columns, new_dtypes)})\n",
    "\n",
    "x_train, ys_train = preprocess(df_train)\n",
    "x_test, ys_test = preprocess(df_test)\n",
    "\n",
    "# display(x_train)\n",
    "# display(ys_train)\n",
    "# display(x_test)\n",
    "# display(ys_test)\n",
    "\n",
    "# display(x_train.columns)\n",
    "# display(ys_train.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, f1_score, roc_auc_score, log_loss\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# テストデータの評価\n",
    "class Result:\n",
    "    def __init__(self, val, proba, optimize=False):\n",
    "        self.val = val\n",
    "        self.proba = proba\n",
    "\n",
    "        if optimize:\n",
    "            def f1_opt(x):\n",
    "                return -f1_score(self.val, self.proba[:, 1] >= x)\n",
    "            result = minimize(f1_opt, x0=np.array([0.5]), method=\"Nelder-Mead\")\n",
    "            threshold = result[\"x\"].item()\n",
    "            self.pred = self.proba[:, 1] >= threshold\n",
    "            self.th = threshold\n",
    "        else:\n",
    "            self.pred = proba.argmax(axis=1)\n",
    "            self.th = 0.5\n",
    "\n",
    "    def acc(self):\n",
    "        return accuracy_score(self.val, self.pred)\n",
    "\n",
    "    def f1(self):\n",
    "        return f1_score(self.val, self.pred, average=\"macro\") \n",
    "\n",
    "    def auc(self):\n",
    "        return roc_auc_score(self.val, self.pred)\n",
    "    \n",
    "    def logloss(self):\n",
    "        return log_loss(self.val, self.proba)\n",
    "\n",
    "    def cm(self):\n",
    "        return confusion_matrix(self.val, self.pred)\n",
    "\n",
    "\n",
    "    # def acc(self):\n",
    "    #     return getattr(self, \"acc_tmp\", self.acc_tmp := accuracy_score(self.val, self.pred))\n",
    "\n",
    "    # def acc(self):\n",
    "    #     attrname = \"acc_tmp\"\n",
    "    #     try:\n",
    "    #         return getattr(self, attrname)\n",
    "    #     except:\n",
    "\n",
    "    #         score = accuracy_score(self.val, self.pred)\n",
    "\n",
    "    #         setattr(self, attrname, score)\n",
    "    #         return getattr(self, attrname)\n",
    "\n",
    "\n",
    "class Scores:\n",
    "    def __init__(self):\n",
    "        self.score_dict = dict()\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.score_dict.setdefault(index, [])\n",
    "    \n",
    "    def __setitem__(self, key, value):\n",
    "        self.score_dict[key] = value\n",
    "        return self\n",
    "        \n",
    "    def __attr__(self, attr):\n",
    "        return self.score_dict.attr\n",
    "\n",
    "    def __or__(self, other):\n",
    "        for k, v in other.score_dict.items():\n",
    "            self.score_dict[k] = v\n",
    "        return self\n",
    "    \n",
    "    def __str__(self):\n",
    "        disp_str = \"\"\n",
    "        for k, v in self.score_dict.items():\n",
    "            if not isinstance(v[0], np.ndarray):\n",
    "                disp_str += f\"{k:8}:{v[0]}\\n\"\n",
    "        \n",
    "        return disp_str[:-1]\n",
    "    \n",
    "    def fold(self, val_index_key, cm_key, proba_key):\n",
    "        s = Scores()\n",
    "        for k, v in self.score_dict.items():\n",
    "            if k == val_index_key:\n",
    "                pass\n",
    "            elif k == cm_key:\n",
    "                s[k].append(np.sum(v, axis=0))\n",
    "            elif k == proba_key:\n",
    "                num_datas = sum(len(sublist) for sublist in self.score_dict[val_index_key])\n",
    "                proba = [None for _ in range(num_datas)]\n",
    "                for val_part, proba_part in zip(self.score_dict[val_index_key], self.score_dict[proba_key]): \n",
    "                    for i, idx in enumerate(val_part):\n",
    "                        proba[idx] = proba_part[i]\n",
    "                s[k].append(proba)\n",
    "            else:\n",
    "                s[k].append(np.mean(v, axis=0))\n",
    "        return s\n",
    "\n",
    "    def ave(self):\n",
    "        s = Scores()\n",
    "        for k, v in self.score_dict.items():\n",
    "            s[k].append(np.mean(v, axis=0))\n",
    "            # if isinstance(v[0], np.ndarray):\n",
    "            #     s[k].append(np.mean(v, axis=0))\n",
    "            # else:\n",
    "            #     s[k].append(sum(v) / len(v))\n",
    "        return s\n",
    "\n",
    "                    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import optuna\n",
    "# Using scikit-learn API\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, f1_score, roc_auc_score, log_loss\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "file_name = \"db.sqlite3\"\n",
    "file_url = fr\"sqlite:///{file_name}\"\n",
    "file_path = Path(fr\"./{file_name}\").resolve()\n",
    "\n",
    "file_path.unlink(missing_ok=True)\n",
    "\n",
    "params_list = []\n",
    "\n",
    "for i, y_train in enumerate(ys_train):\n",
    "\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            \"boosting_type\": \"gbdt\",\n",
    "            'objective': 'binary',\n",
    "            \"n_estimators\": 100,\n",
    "            \"learning_rate\": 0.1,\n",
    "\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 1, 7), # 10\n",
    "            \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.4, 1.0),\n",
    "            \"num_leaves\": trial.suggest_int(\"num_leaves\", 25, 60), # 31\n",
    "            \"subsample\": trial.suggest_float(\"subsample\", 0.4, 1.0), # 1.0 bagging_fracation\n",
    "\n",
    "            \"task\": \"train\",\n",
    "            'metric':'binary_logloss',\n",
    "            'seed': 0,\n",
    "            'verbosity': -1,\n",
    "        }\n",
    "        \n",
    "        global x_train\n",
    "        \n",
    "        f = Scores()\n",
    "        for ri in range(4):\n",
    "            kf = KFold(n_splits=4, shuffle=True, random_state=ri)\n",
    "            \n",
    "            s = Scores()\n",
    "            for fold, (train_indices, val_indices) in enumerate(kf.split(x_train)):\n",
    "                x_train_f, x_val_f = x_train[train_indices], x_train[val_indices]\n",
    "                y_train_f, y_val_f = y_train[train_indices], y_train[val_indices]\n",
    "                \n",
    "                model = lgb.LGBMClassifier(**params)\n",
    "                model.fit(x_train_f, y_train_f)\n",
    "\n",
    "                y_proba = model.predict_proba(x_val_f)\n",
    "\n",
    "                r = Result(y_val_f, y_proba)\n",
    "                s[\"acc\"].append(r.acc())\n",
    "                s[\"f1\"].append(r.f1())\n",
    "                s[\"auc\"].append(r.auc())\n",
    "                s[\"logloss\"].append(r.logloss())\n",
    "                s[\"cm\"].append(r.cm())\n",
    "                s[\"proba\"].append(r.proba)\n",
    "                s[\"ind\"].append(val_indices)\n",
    "                s[\"feat_imp\"].append(model.feature_importances_)\n",
    "\n",
    "            f |= s.fold(\"ind\", \"cm\", \"proba\")\n",
    "\n",
    "        a = f.ave()\n",
    "\n",
    "        return a[\"logloss\"][0]\n",
    "\n",
    "\n",
    "    study = optuna.create_study(\n",
    "        storage=file_url,\n",
    "        study_name=f\"xxxx\",\n",
    "        direction='minimize',\n",
    "        load_if_exists=True,\n",
    "    )\n",
    "    study.optimize(objective, n_trials=50)\n",
    "\n",
    "    params = {\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        'objective': 'binary',\n",
    "        \"n_estimators\": 100,\n",
    "        \"learning_rate\": 0.1,\n",
    "\n",
    "        \"task\": \"train\",\n",
    "        'metric':'binary_logloss',\n",
    "        'seed': 0,\n",
    "        'verbosity': -1,\n",
    "    }\n",
    "    params |= study.best_params\n",
    "    params_list.append(params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using scikit-learn API\n",
    "df_probas = None\n",
    "\n",
    "ths = []\n",
    "\n",
    "for y_train, params in zip(ys_train, params_list):\n",
    "\n",
    "    global x_train\n",
    "    \n",
    "    f = Scores()\n",
    "    for ri in range(4):\n",
    "        kf = KFold(n_splits=4, shuffle=True, random_state=ri)\n",
    "        \n",
    "        s = Scores()\n",
    "        for fold, (train_indices, val_indices) in enumerate(kf.split(x_train)):\n",
    "            x_train_f, x_val_f = x_train[train_indices], x_train[val_indices]\n",
    "            y_train_f, y_val_f = y_train[train_indices], y_train[val_indices]\n",
    "            \n",
    "            model = lgb.LGBMClassifier(**params)\n",
    "            model.fit(x_train_f, y_train_f)\n",
    "            \n",
    "            y_proba = model.predict_proba(x_val_f)\n",
    "\n",
    "            r = Result(y_val_f, y_proba, optimize=True)\n",
    "            s[\"acc\"].append(r.acc())\n",
    "            s[\"f1\"].append(r.f1())\n",
    "            s[\"th\"].append(r.th)\n",
    "            s[\"logloss\"].append(r.logloss())\n",
    "            s[\"cm\"].append(r.cm())\n",
    "            s[\"proba\"].append(r.proba)\n",
    "            s[\"ind\"].append(val_indices)\n",
    "            s[\"feat_imp\"].append(model.feature_importances_)\n",
    "            \n",
    "\n",
    "        f |= s.fold(\"ind\", \"cm\", \"proba\")\n",
    "    a = f.ave()\n",
    "\n",
    "    ths.append(a[\"th\"][0])\n",
    "\n",
    "\n",
    "    print(f\"-- {y_train.name} --\")\n",
    "    print(a)\n",
    "    print()\n",
    "    print(\"- importance\")\n",
    "\n",
    "    cf = {c: f for c, f in zip(x_train.columns, a[\"feat_imp\"][0])}\n",
    "    cf = {k: v for k, v in sorted(cf.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "    for c, f in cf.items():\n",
    "        print(f\"{c:30}:{f}\")\n",
    "\n",
    "    Path(f\"./{train_type}\").mkdir(parents=True, exist_ok=True)\n",
    "    with open(file=f\"./{train_type}/metrics_{y_train.name}.txt\", mode=\"w\") as fh:\n",
    "        print(f\"-- {y_train.name} --\", file=fh)\n",
    "        print(a, file=fh)\n",
    "\n",
    "        print(file=fh)\n",
    "        print(\"- importance\", file=fh)\n",
    "        for c, f in cf.items():\n",
    "            print(f\"{c:30}:{f}\", file=fh)\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_figwidth(3)\n",
    "    fig.set_figheight(2.25)\n",
    "\n",
    "    ax = sns.heatmap(a[\"cm\"][0], annot=True, cbar=True, square=True, fmt=\".0f\", cmap=\"Blues_r\", xticklabels=list(range(a[\"cm\"][0].shape[0])), yticklabels=list(range(a[\"cm\"][0].shape[1])))\n",
    "    fig.savefig(f\"./{train_type}/cv_{y_train.name}.png\")\n",
    "    fig.show()\n",
    "    ax.set_xlabel(\"pred_label\")\n",
    "    ax.set_ylabel(\"true_label\")\n",
    "\n",
    "\n",
    "    fig, axs = plt.subplots(2, sharex=True, gridspec_kw={'hspace': 0})\n",
    "\n",
    "    axs[0].set_ylim(0, 30)  # invert the axis\n",
    "    sns.histplot(a[\"proba\"][0][:, 1][y_train == 0], ax=axs[0], color='blue', bins=50)\n",
    "    axs[0].xaxis.tick_top()  # and move the X-Axis\n",
    "\n",
    "    axs[1].set_ylim(axs[0].get_ylim()[::-1])  # invert the axis\n",
    "    sns.histplot(a[\"proba\"][0][:, 1][y_train == 1], ax=axs[1], color='red', bins=50)\n",
    "    axs[1].xaxis.tick_top()  # and move the X-Axis\n",
    "    \n",
    "    axs[0].axvline(x=a[\"th\"][0], color='r', linestyle='--')\n",
    "    axs[1].axvline(x=a[\"th\"][0], color='r', linestyle='--')\n",
    "\n",
    "# Remove space between subplots\n",
    "    fig.subplots_adjust(hspace=0)\n",
    "\n",
    "# Show the plot\n",
    "    fig.savefig(f\"./{train_type}/dist_{y_train.name}.png\")\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "    df_proba = pl.Series(a[\"proba\"][0][:, 1]).rename(y_train.name + \"_prob\").to_frame()\n",
    "    df_proba = df_proba.with_columns(\n",
    "        pl.when(pl.all() < a[\"th\"][0])\n",
    "        .then(pl.lit(\"N\"))\n",
    "        .otherwise(pl.lit(\"Y\"))\n",
    "        .name\n",
    "        .map(lambda x: x[:-5] + \"_pred\")\n",
    "    )\n",
    "    if df_probas is None:\n",
    "        df_probas = df_proba\n",
    "    else:\n",
    "        df_probas = pl.concat([df_probas, df_proba], how=\"horizontal\")\n",
    "\n",
    "df_pred_train = pl.concat([df_train, df_probas], how=\"horizontal\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using scikit-learn API\n",
    "df_probas = None\n",
    "\n",
    "for y_train, y_test, params, th in zip(ys_train, ys_test, params_list, ths):\n",
    "    model = lgb.LGBMClassifier(**params)\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    y_proba = model.predict_proba(x_test)\n",
    "\n",
    "    a_test = Scores()\n",
    "    r = Result(y_test, y_proba)\n",
    "    a_test[\"proba\"].append(r.proba)\n",
    "\n",
    "    df_proba = pl.Series(a_test[\"proba\"][0][:, 1]).rename(y_test.name + \"_prob\").to_frame()\n",
    "    df_proba = df_proba.with_columns(\n",
    "        pl.when(pl.all() < th)\n",
    "        .then(pl.lit(\"N\"))\n",
    "        .otherwise(pl.lit(\"Y\"))\n",
    "        .name\n",
    "        .map(lambda x: x[:-5] + \"_pred\")\n",
    "\n",
    "    )\n",
    "    if df_probas is None:\n",
    "        df_probas = df_proba\n",
    "    else:\n",
    "        df_probas = pl.concat([df_probas, df_proba], how=\"horizontal\")\n",
    "\n",
    "df_pred_test = pl.concat([df_test, df_probas], how=\"horizontal\")\n",
    "\n",
    "\n",
    "df_pred_test = pl.concat([df_pred_train, df_pred_test], how=\"vertical\").sort(\"xxx\")\n",
    "df_pred_test.write_csv(f\"./{train_type}/prediction_{train_type}.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
