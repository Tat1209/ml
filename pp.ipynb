{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from pathlib import Path\n",
    "\n",
    "# dfを渡すと、col_nameで重複する要素に番号を順番に付与し、col_nameをユニークに\n",
    "def suffix_dupes(df, col_name):\n",
    "    item_df = df.select(col_name)\n",
    "    # 重複する要素のseriesを作成\n",
    "    dups_ser = item_df.filter(pl.col(col_name).is_duplicated()).unique().to_series()\n",
    "    dup_d = {ele:0 for ele in dups_ser}\n",
    "    # 新しい列を作成するための空のリストを用意\n",
    "    item_ser = item_df.to_series()\n",
    "    new_col = []\n",
    "    for i in item_ser:\n",
    "        if i in dups_ser: # 要素が重複リストに含まれる場合\n",
    "            new_i = i + str(dup_d[i]) # 要素の後ろに数字を付ける\n",
    "            dup_d[i]+= 1\n",
    "            new_col.append(new_i)\n",
    "        else: new_col.append(i)\n",
    "    new_col = pl.Series(col_name, new_col)\n",
    "    df = df.with_columns(new_col)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# dfを渡すと、col_nameの要素に番号を順番に付与し、col_nameをユニークに\n",
    "def shuffix_col(df, col_name):\n",
    "    item_ser = df.select(col_name).to_series()\n",
    "    item_d = {ele:0 for ele in item_ser}\n",
    "    # 新しい列を作成するための空のリストを用意\n",
    "    new_col = []\n",
    "    for i in item_ser:\n",
    "        new_i = i + str(item_d[i]) # 要素の後ろに数字を付ける\n",
    "        item_d[i]+= 1\n",
    "        new_col.append(new_i)\n",
    "    new_col = pl.Series(col_name, new_col)\n",
    "    df = df.with_columns(new_col)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def create_combination_columns(df, column):\n",
    "    items_l = df.select(column).to_series()\n",
    "    \n",
    "    new_df = None\n",
    "    for i, item in enumerate(items_l):\n",
    "        item_row = df.select(pl.all().exclude(column))[i]\n",
    "        new_column_names = [item + \"_\" + name for name in item_row.columns] # .suffixで代用可?\n",
    "\n",
    "        item_row.columns = new_column_names\n",
    "        if new_df is None: new_df = item_row\n",
    "        else: new_df = new_df.with_columns(item_row)\n",
    "    \n",
    "    return new_df\n",
    "\n",
    "\n",
    "def column_to_feature(df, uq_col, featured_col):\n",
    "    new_df = None\n",
    "    id_uq = df[uq_col].unique()\n",
    "\n",
    "    for id in id_uq:\n",
    "        df_id = df.filter(pl.col(uq_col)==id)\n",
    "        df_id = shuffix_col(df_id, featured_col).sort(featured_col)\n",
    "\n",
    "\n",
    "        col_index = df_id.get_column_index(featured_col)\n",
    "        df_right = df_id.select(df_id.columns[col_index:])\n",
    "        df_left = df_id.select(df_id.columns[:col_index])\n",
    "\n",
    "        df_left_chara = df_left[0]  # 同じデータが並んでいるので、最初の一行だけとってくる\n",
    "        df_right_chara = create_combination_columns(df_right, featured_col)\n",
    "\n",
    "        df_rec = pl.concat([df_left_chara, df_right_chara], how=\"horizontal\")\n",
    "        \n",
    "        if new_df is None: new_df = df_rec\n",
    "        else: new_df = pl.concat([new_df, df_rec], how=\"diagonal\")\n",
    "        \n",
    "    return new_df\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_ndat = Path(\"xxx\")\n",
    "path_tdat = Path(\"xxx\")\n",
    "path_catch = Path(\"xxx\")\n",
    "\n",
    "# df = pl.read_csv(path, ignore_errors=True)\n",
    "df_ndat = pl.read_csv(path_ndat, infer_schema_length=1000)\n",
    "df_tdat = pl.read_csv(path_tdat, infer_schema_length=1000)\n",
    "df_catch = pl.read_csv(path_catch, infer_schema_length=1000)\n",
    "\n",
    "\n",
    "\n",
    "df_ndat = column_to_feature(df_ndat, \"xxx\", \"xxx\")\n",
    "df_tdat = column_to_feature(df_tdat, \"xxx\", \"xxx\")\n",
    "\n",
    "df = pl.concat([df_ndat, df_tdat], how=\"align\")\n",
    "\n",
    "\n",
    "df_total = df_ndat.join(df_tdat, on=df_ndat.columns[:2], how='outer_coalesce')\n",
    "df_total = df_total.join(df_catch, on=df_ndat.columns[:2], how='outer_coalesce')\n",
    "\n",
    "\n",
    "df_ndat.write_csv(\"xxx.csv\")\n",
    "df_tdat.write_csv(\"xxx.csv\")\n",
    "df_total.write_csv(\"xxx.csv\")\n",
    "\n",
    "\n",
    "with open(\"./tmp.txt\", \"w\") as f:\n",
    "    with pl.Config() as cfg:\n",
    "        cfg.set_tbl_rows(-1)\n",
    "        cfg.set_tbl_cols(-1)\n",
    "\n",
    "        non_null_counts = {col: [df[col].is_not_null().sum()] for col in df.columns}\n",
    "        non_null_counts = pl.DataFrame(non_null_counts)\n",
    "        print(non_null_counts, file=f)\n",
    "        \n",
    "            \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
